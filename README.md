# ğŸ” Research Rabbit Hole

> An intelligent deep research agent system built with LangGraph, FastAPI, and Streamlit that autonomously conducts comprehensive multi-agent research investigations.

A production-ready multi-agent research framework that combines user intent clarification, AI-powered research coordination, and intelligent report generation. Built with modern async Python, streaming APIs, and advanced LLM orchestration.

## ğŸ¯ What This Does

The **Research Rabbit Hole** system helps you conduct deep, thorough research on any topic by:

1. **Understanding your intent** - Uses AI to clarify vague research requests and generate detailed research briefs
2. **Coordinating multi-agent research** - Deploys specialized research agents that work in parallel on different aspects of your topic
3. **Generating comprehensive reports** - Synthesizes findings into well-structured reports with citations and key insights

Perfect for market analysis, competitive intelligence, technical research, academic deep-dives, and any scenario requiring exhaustive information gathering.

### Key Capabilities

âœ¨ **Multi-Agent Coordination** - Supervisor agent directs specialized researchers  
âœ¨ **Intelligent Scoping** - Auto-clarifies ambiguous requests before research starts  
âœ¨ **Real-time Streaming** - See research progress as it happens  
âœ¨ **File & Web Access** - Research agents can read files and search the web  
âœ¨ **Configurable Depth** - Control research breadth (shallow/moderate/deep)  
âœ¨ **Thread-based History** - Maintain persistent research conversations  
âœ¨ **LangSmith Integration** - Full observability and feedback tracking

## ğŸ—ï¸ System Architecture

```
User Input (Streamlit UI)
         â†“
    [FastAPI Service]
         â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Deep Research Agent (LangGraph)           â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚  â”‚ 1ï¸âƒ£  SCOPING PHASE                    â”‚   â”‚
    â”‚  â”‚ â”œâ”€ Intent Clarification              â”‚   â”‚
    â”‚  â”‚ â”‚  (Ask clarifying questions)        â”‚   â”‚
    â”‚  â”‚ â”œâ”€ Research Brief Generation         â”‚   â”‚
    â”‚  â”‚ â”‚  (Structured research plan)        â”‚   â”‚
    â”‚  â”‚ â””â”€ Key Areas Extraction             â”‚   â”‚
    â”‚  â”‚    (Topics to cover)                 â”‚   â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â”‚                 â†“                            â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚  â”‚ 2ï¸âƒ£  RESEARCH PHASE                   â”‚   â”‚
    â”‚  â”‚ â”œâ”€ Supervisor Agent                  â”‚   â”‚
    â”‚  â”‚ â”‚  (Coordinates research)            â”‚   â”‚
    â”‚  â”‚ â”œâ”€ Researcher Agents (Parallel)      â”‚   â”‚
    â”‚  â”‚ â”‚  â”œâ”€ Web Search Researcher          â”‚   â”‚
    â”‚  â”‚ â”‚  â”œâ”€ Document Analysis Researcher   â”‚   â”‚
    â”‚  â”‚ â”‚  â””â”€ Data Analyst                   â”‚   â”‚
    â”‚  â”‚ â””â”€ Tools Available:                 â”‚   â”‚
    â”‚  â”‚    â”œâ”€ Web Search (DuckDuckGo)       â”‚   â”‚
    â”‚  â”‚    â”œâ”€ File Reading                   â”‚   â”‚
    â”‚  â”‚    â””â”€ Calculator                     â”‚   â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â”‚                 â†“                            â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚  â”‚ 3ï¸âƒ£  REPORT PHASE                     â”‚   â”‚
    â”‚  â”‚ â”œâ”€ Synthesize Findings               â”‚   â”‚
    â”‚  â”‚ â”œâ”€ Format Report                     â”‚   â”‚
    â”‚  â”‚ â””â”€ Extract Key Insights              â”‚   â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
    [Stream to UI]
         â†“
    User Feedback & Message History
```

### Data Flow

**Synchronous (Fast Response)**: User â†’ Service â†’ Agent â†’ Final Report â†’ UI  
**Streaming (Live Updates)**: User â†’ Service â†’ Agent â†’ (token + message chunks) â†’ UI  
**History**: Thread-based conversation storage with state persistence

## ğŸ¤– Agents Overview

### Deep Research Agent (Primary)

The main agent that orchestrates the complete research workflow with three distinct phases:

#### Phase 1: Scoping (`research_agent_scope.py`)

Clarifies user intent and generates a structured research plan before expensive research begins.

| Component                    | Purpose                                                                                                    |
| ---------------------------- | ---------------------------------------------------------------------------------------------------------- |
| **Intent Clarifier**         | Uses structured output to determine if user request is specific enough. If not, asks clarifying questions. |
| **Research Brief Generator** | Transforms conversation into detailed research brief with key areas to cover and desired depth.            |
| **State Updater**            | Enriches graph state with `research_brief`, `brief_key_areas`, `brief_depth` for next phase.               |

**Key Files**:

- `src/agents/deep_research_agent/research_agent_scope.py` - Scoping workflow
- `src/agents/deep_research_agent/prompts.py` - Prompts for clarification and brief generation

#### Phase 2: Research (`supervisor.py` + `research_agent.py`)

Multi-agent coordination where a supervisor delegates research to specialized agents.

| Component             | Purpose                                                                                                            |
| --------------------- | ------------------------------------------------------------------------------------------------------------------ |
| **Supervisor Agent**  | Reads research brief, delegates tasks to researchers, manages iteration limits, and coordinates parallel research. |
| **Researcher Agents** | Specialized agents that execute research tasks using available tools. Run concurrently to maximize efficiency.     |
| **Tools**             | Web search (DuckDuckGo), file reading, calculator, thinking/reflection.                                            |

**Configuration**:

```python
max_concurrent_researchers = 3    # Max parallel research agents
max_researcher_iterations = 10    # Iteration limit per research session
```

**Key Files**:

- `src/agents/deep_research_agent/supervisor.py` - Supervisor orchestration logic
- `src/agents/deep_research_agent/research_agent.py` - Individual researcher agent
- `src/agents/tools.py` - Research tools (web search, file I/O, etc.)

#### Phase 3: Report Generation (`deep_researcher.py`)

Synthesizes research findings into a structured, readable report.

| Component              | Purpose                                                               |
| ---------------------- | --------------------------------------------------------------------- |
| **Report Compiler**    | Formats findings, extracts key insights, generates final report text. |
| **Message Aggregator** | Combines all research notes and outputs into coherent narrative.      |

**Key Files**:

- `src/agents/deep_research_agent/deep_researcher.py` - Phase orchestration
- `src/agents/deep_research_agent/state.py` - State schema and tool definitions

### State Management (`state.py`)

```python
@dataclass
class DeepResearchState:
    messages: list[ChatMessage]              # Conversation history
    research_brief: str                      # Generated research plan
    brief_key_areas: list[str]              # Topics to research
    brief_depth: str                         # shallow|moderate|deep
    notes: list[str]                         # Research findings
    # ... other fields
```

### Research Tools

Agents have access to:

- **Web Search** (`duckduckgo-search`) - Real-time internet search
- **File Reading** - Load and analyze documents
- **Calculator** - Numerical computations
- **Think** - Reflection tool for planning

## ğŸ› ï¸ Technical Stack

| Layer             | Technology     | Purpose                                                  |
| ----------------- | -------------- | -------------------------------------------------------- |
| **Orchestration** | LangGraph v1.0 | Agent state machine, streaming, Command routing          |
| **LLMs**          | LangChain      | Multi-provider support (OpenAI, Anthropic, Google, etc.) |
| **Backend**       | FastAPI        | REST API with SSE streaming                              |
| **Frontend**      | Streamlit      | Web UI for chat and configuration                        |
| **Data**          | Pydantic       | Type-safe schemas and validation                         |
| **Storage**       | In-Memory      | Checkpoint storage for conversation state                |
| **Observability** | LangSmith      | Run tracing, feedback recording, debugging               |
| **Search**        | DuckDuckGo     | Web search for research                                  |

## âš¡ Quick Start

### Prerequisites

- Python 3.11+
- At least one LLM API key (OpenAI, Anthropic, etc.)

### Option 1: Local Python Setup

```bash
# Clone and setup
git clone https://github.com/yourusername/research-rabbit-hole.git
cd research-rabbit-hole

# Install uv (recommended) or use pip
curl -LsSf https://astral.sh/uv/install.sh | sh

# Create environment and install dependencies
uv sync --frozen
source .venv/bin/activate

# Configure API key
echo 'OPENAI_API_KEY=your_key_here' >> .env

# Terminal 1: Start FastAPI service
python src/run_service.py

# Terminal 2: Start Streamlit app
streamlit run src/streamlit_app.py
```

The app opens at `http://localhost:8501`  
API available at `http://localhost:8080`

### Option 2: Docker Setup (Recommended)

```bash
git clone https://github.com/yourusername/research-rabbit-hole.git
cd research-rabbit-hole

# Configure
echo 'OPENAI_API_KEY=your_key_here' >> .env

# Launch with auto-reload
docker compose watch
```

Then navigate to `http://localhost:8501`

## ğŸ“‚ Project Structure

```
research-rabbit-hole/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/                          # Agent implementations
â”‚   â”‚   â”œâ”€â”€ deep_research_agent/        # Main research agent (3-phase system)
â”‚   â”‚   â”‚   â”œâ”€â”€ deep_researcher.py      # Phase orchestrator (START â†’ scoping â†’ research â†’ report â†’ END)
â”‚   â”‚   â”‚   â”œâ”€â”€ research_agent_scope.py # Phase 1: Intent clarification & brief generation
â”‚   â”‚   â”‚   â”œâ”€â”€ supervisor.py           # Phase 2: Multi-agent research coordinator
â”‚   â”‚   â”‚   â”œâ”€â”€ research_agent.py       # Phase 2: Individual researcher agents
â”‚   â”‚   â”‚   â”œâ”€â”€ prompts.py              # LLM system & user prompts
â”‚   â”‚   â”‚   â”œâ”€â”€ state.py                # Graph state schema & tool definitions
â”‚   â”‚   â”‚   â””â”€â”€ utils.py                # Helper functions
â”‚   â”‚   â”œâ”€â”€ agents.py                   # Agent registry & loading
â”‚   â”‚   â”œâ”€â”€ tools.py                    # Shared research tools
â”‚   â”‚   â””â”€â”€ lazy_agent.py               # Async agent loading
â”‚   â”‚
â”‚   â”œâ”€â”€ service/                         # FastAPI backend
â”‚   â”‚   â”œâ”€â”€ service.py                  # Main service with /invoke & /stream endpoints
â”‚   â”‚   â””â”€â”€ utils.py                    # Message conversion helpers
â”‚   â”‚
â”‚   â”œâ”€â”€ client/                          # Client library
â”‚   â”‚   â””â”€â”€ client.py                   # Async/sync client for service interaction
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                            # Core utilities
â”‚   â”‚   â”œâ”€â”€ llm.py                      # LLM provider initialization
â”‚   â”‚   â””â”€â”€ settings.py                 # Configuration & environment variables
â”‚   â”‚
â”‚   â”œâ”€â”€ schema/                          # Data models
â”‚   â”‚   â”œâ”€â”€ models.py                   # LLM model enums
â”‚   â”‚   â””â”€â”€ schema.py                   # Chat messages, service schemas
â”‚   â”‚
â”‚   â”œâ”€â”€ streamlit_app.py                 # Web UI (chat interface)
â”‚   â”œâ”€â”€ run_service.py                   # Service entry point
â”‚   â””â”€â”€ run_agent.py                     # Direct agent invocation
â”‚
â”œâ”€â”€ docker/                              # Docker configurations
â”‚   â”œâ”€â”€ Dockerfile.app                  # Streamlit app container
â”‚   â””â”€â”€ Dockerfile.service              # FastAPI service container
â”‚
â”œâ”€â”€ compose.yaml                         # Docker Compose (multi-service setup)
â”œâ”€â”€ pyproject.toml                       # Dependencies & project metadata
â”œâ”€â”€ .env.example                         # Environment variable template
â””â”€â”€ tests/                               # Unit & integration tests
```

## ğŸ”§ Configuration

### Environment Variables (`.env`)

**Required** (at least one LLM):

```bash
OPENAI_API_KEY=sk-...                   # OpenAI
# OR
ANTHROPIC_API_KEY=sk-ant-...            # Anthropic Claude
# OR
GROQ_API_KEY=...                        # Groq (with Llama models)
```

**Optional** (agent behavior):

```bash
DEFAULT_MODEL=gpt-4o                    # Default LLM to use
DEFAULT_AGENT=deep-research-agent       # Default agent

# Research depth: shallow, moderate, deep
RESEARCH_DEPTH=moderate

# Max concurrent researchers (1-5)
MAX_CONCURRENT_RESEARCHERS=3

# Max iterations per research session
MAX_RESEARCH_ITERATIONS=10
```

**Optional** (observability):

```bash
LANGSMITH_API_KEY=...                   # LangSmith tracing
LANGFUSE_TRACING=true                   # Langfuse observability
```

See [`.env.example`](./.env.example) for complete list.


## ğŸ“¦ Dependencies

### Key Packages

- **langchain** - LLM abstractions & utilities
- **langgraph** - Agent orchestration & state management
- **fastapi** - REST API framework
- **streamlit** - Web UI
- **pydantic** - Data validation
- **duckduckgo-search** - Web search
- **langsmith** - Observability

See `pyproject.toml` for complete list with versions.

## ğŸ¤ Contributing

Contributions welcome! Please:

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/your-feature`
3. Make changes and add tests
4. Run: `pytest` and `pre-commit run --all-files`
5. Push and create a Pull Request

### Development Setup

```bash
uv sync --frozen
pre-commit install
```

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file

## ğŸ™ Credits

Built with:

- [LangChain](https://python.langchain.com/) - LLM framework
- [LangGraph](https://langchain-ai.github.io/langgraph/) - Agent orchestration
- [FastAPI](https://fastapi.tiangolo.com/) - Web framework
- [Streamlit](https://streamlit.io/) - Web UI
- [LangSmith](https://smith.langchain.com/) - Observability

